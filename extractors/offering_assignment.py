# offering_assignment.py - Generated by Extractor Generator Tool
"""
OfferingAssignmentExtractor - Data extractor for OFFERING_ASSIGNMENT table

Generated on: 2025-12-11 14:55:10
CSV Inputs: OfferedCourses
Dependencies: OFFERING, TEACHER

This extractor follows the DataExtractor contract for the database population system.
Modify the extract() method to implement your specific business logic.
"""

import pandas as pd
import logging
import csv
from pathlib import Path
from typing import Dict, List, Any
from base_extractor import DataExtractor

logger = logging.getLogger(__name__)


class OfferingAssignmentExtractor(DataExtractor):
    """Extract data for OFFERING_ASSIGNMENT table"""
    
    @property
    def table_name(self) -> str:
        """Return the database table name this extractor targets"""
        return "OFFERING_ASSIGNMENT"
    
    @property
    def dependencies(self) -> List[str]:
        """Return list of table names this extractor depends on"""
        return ['OFFERING', 'TEACHER', 'SUBJECT', 'SEMESTER_PLANNING']
    
    def extract(self, OfferedCourses: pd.DataFrame, offering: List[Dict[str, Any]], teacher: List[Dict[str, Any]], subject: List[Dict[str, Any]] = None, **kwargs) -> List[Dict[str, Any]]:
        """
        Extract data for OFFERING_ASSIGNMENT table.
        
        Args:
        CSV Data:
            OfferedCourses: DataFrame loaded from OfferedCourses.csv
        Dependencies:
            offering: List of OFFERING table records from dependency resolution
            teacher: List of TEACHER table records from dependency resolution
        Additional:
            **kwargs: Additional parameters passed by the extraction system
        
        Returns:
            List of dictionaries representing OFFERING_ASSIGNMENT table records
        """
        if not offering or not teacher or not subject:
            logger.warning("Missing dependencies")
            return []

        def normalize_text(value: Any) -> str:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return None
            text = str(value).strip()
            if not text:
                return None
            return " ".join(text.split()).lower()

        def normalize_program(value: Any) -> str:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return None
            text = str(value).strip()
            if not text:
                return None
            return text.upper()

        def normalize_semester(value: Any) -> int:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return None
            try:
                return int(float(value))
            except (ValueError, TypeError):
                return None

        def normalize_term(value: Any) -> str:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return None
            text = str(value).strip()
            if not text:
                return None
            return text.upper()

        def parse_hours(value: Any) -> float:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return 0.0
            if isinstance(value, str):
                text = value.strip().replace(',', '.')
                if not text:
                    return 0.0
                try:
                    return float(text)
                except ValueError:
                    return 0.0
            try:
                return float(value)
            except (TypeError, ValueError):
                return 0.0

        def normalize_sbjno(value: Any) -> str:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return None
            text = str(value).strip()
            return text if text else None

        def normalize_lecno(value: Any) -> int:
            if value is None or (isinstance(value, float) and pd.isna(value)):
                return None
            try:
                return int(float(value))
            except (ValueError, TypeError):
                return None

        def load_shared_lecture_map() -> Dict[tuple, str]:
            data_dir = Path(__file__).resolve().parent.parent / 'data'
            map_path = data_dir / 'shared_lecture_map.csv'
            if not map_path.exists():
                fallback_path = data_dir / 'shared_lecture.csv'
                if fallback_path.exists():
                    map_path = fallback_path
                else:
                    logger.info("shared_lecture_map.csv not found; skipping shared lecture mapping")
                    return {}
            try:
                df_map = pd.read_csv(
                    map_path,
                    sep=';',
                    encoding='utf-8',
                    dtype=str,
                    on_bad_lines='skip',
                    engine='python',
                    quoting=csv.QUOTE_NONE,
                )
            except Exception:
                df_map = pd.read_csv(
                    map_path,
                    sep=';',
                    encoding='latin-1',
                    dtype=str,
                    on_bad_lines='skip',
                    engine='python',
                    quoting=csv.QUOTE_NONE,
                )

            shared_map = {}
            for _, row in df_map.iterrows():
                sbj_no = normalize_sbjno(row.get('sbjNo'))
                term = normalize_term(row.get('term'))
                lec_no = normalize_lecno(row.get('lecNo'))
                group_id = normalize_sbjno(row.get('shared_group_id'))
                if not sbj_no or not term or lec_no is None or not group_id:
                    continue
                key = (sbj_no, term, lec_no)
                if key in shared_map and shared_map[key] != group_id:
                    logger.warning(
                        f"Conflicting shared_group_id for {key}: "
                        f"{shared_map[key]} vs {group_id}"
                    )
                    continue
                shared_map[key] = group_id
            return shared_map

        # Create offering lookup by subject+term
        offering_by_subj_term = {}
        for o in offering:
            key = (o['FK_S_ID'], o['FK_SP_ID'])
            offering_by_subj_term[key] = o

        # Create subject lookup by natural key
        subject_lookup = {}
        for s in subject:
            key = (
                normalize_text(s.get('S_NAME')),
                normalize_semester(s.get('S_SEMESTER')),
                normalize_program(s.get('FK_ST_NAME')),
            )
            if None in key:
                continue
            if key in subject_lookup:
                logger.warning(f"Duplicate subject key {key}, keeping first match")
                continue
            subject_lookup[key] = s['S_ID']

        # Create semester lookup
        semester_lookup = {}
        if 'semester_planning' in kwargs:
            for s in kwargs['semester_planning']:
                term_key = normalize_term(s.get('SP_TERM'))
                if term_key:
                    semester_lookup[term_key] = s['SP_ID']

        teacher_ids = {t['T_ID'] for t in teacher}

        shared_map = load_shared_lecture_map()

        base_cols = ['lecNo', 'sbjNo', 'sbjName', 'sbjlevel', 'studyPrg', 'term', 'cntLec']
        if 'numSchd' in OfferedCourses.columns:
            base_cols.append('numSchd')
        df = OfferedCourses[base_cols].copy()
        df['teacher_id'] = pd.to_numeric(df['lecNo'], errors='coerce')
        df['sbjName_norm'] = df['sbjName'].apply(normalize_text)
        df['sbjlevel_norm'] = df['sbjlevel'].apply(normalize_semester)
        df['studyPrg_norm'] = df['studyPrg'].apply(normalize_program)
        df['term_norm'] = df['term'].apply(normalize_term)
        df['sbjNo_norm'] = df['sbjNo'].apply(normalize_sbjno)
        df['cntLec'] = df['cntLec'].apply(parse_hours)
        if 'numSchd' in df.columns:
            df['numSchd'] = pd.to_numeric(df['numSchd'], errors='coerce').fillna(0)
        else:
            df['numSchd'] = 0

        df = df.dropna(subset=['teacher_id', 'sbjName_norm', 'sbjlevel_norm', 'studyPrg_norm', 'term_norm'])
        df['teacher_id'] = df['teacher_id'].astype(int)

        def resolve_group(group: pd.DataFrame) -> pd.Series:
            shared_ids = [v for v in group['shared_group_id'] if v]
            unique_ids = list(dict.fromkeys(shared_ids))
            if len(unique_ids) > 1:
                logger.warning(
                    "Multiple shared_group_id values for "
                    f"{group.name}: {unique_ids}. Using {unique_ids[0]}"
                )
            return pd.Series({
                'cntLec': group['cntLec'].sum(),
                'numSchd': group['numSchd'].sum(),
                'shared_group_id': unique_ids[0] if unique_ids else None,
            })

        df['shared_group_id'] = df.apply(
            lambda r: shared_map.get((r['sbjNo_norm'], r['term_norm'], r['teacher_id'])),
            axis=1,
        )
        df = (
            df.groupby(
                ['teacher_id', 'sbjName_norm', 'sbjlevel_norm', 'studyPrg_norm', 'term_norm'],
                as_index=False,
            )
            .apply(resolve_group)
            .reset_index()
        )
        
        records = []
        id_counter = 1
        
        missing_subject = 0
        missing_semester = 0
        missing_offering = 0

        for _, row in df.iterrows():
            teacher_id = row['teacher_id']
            if teacher_id not in teacher_ids:
                continue

            subject_key = (row['sbjName_norm'], row['sbjlevel_norm'], row['studyPrg_norm'])
            subject_id = subject_lookup.get(subject_key)
            semester_id = semester_lookup.get(row['term_norm'])

            if subject_id is None:
                missing_subject += 1
                continue
            if semester_id is None:
                missing_semester += 1
                continue

            offering_rec = offering_by_subj_term.get((subject_id, semester_id))
            if not offering_rec:
                missing_offering += 1
                continue
            
            record = {
                'OA_ID': id_counter,
                'FK_O_ID': offering_rec['O_ID'],
                'FK_T_ID': teacher_id,
                'OA_ASSIGNED_HOURS': float(row['cntLec']),
                'OA_ACTUAL_HOURS': float(row['numSchd']),
                'OA_SHARED_GROUP_ID': row.get('shared_group_id'),
                'OA_ROLE': None

            }
            records.append(record)
            id_counter += 1

        if missing_subject:
            logger.warning(f"{missing_subject} assignments skipped (subject not found)")
        if missing_semester:
            logger.warning(f"{missing_semester} assignments skipped (semester not found)")
        if missing_offering:
            logger.warning(f"{missing_offering} assignments skipped (offering not found)")
        
        logger.info(f"{self.__class__.__name__} extracted {len(records)} records")
        return records
